---
layout: post
title: MLOps Zero to Hero 15 - kfp(kubflow pipeline) SDK
tags: [MLOps]
use_math: true
---

# Overview

Kfp(kubeflow pipeline)은 kubeflow echo system의 한 부분으로, 대규모 ML 모델을 train 및 test하고 이를 효과적으로 관리할 수 있게 도와줍니다. Kfp는 Kubeflow의 가장 중요한 기능 중 하나이며, ML Experiment를 reproducible, reusable하게 만듭니다.

Pipeline의 각 node는 container이며, DAG(Directed Acyclic Graph)로 표현됩니다.

> kfp example

![](https://user-images.githubusercontent.com/31475037/112990077-98d7b380-91a0-11eb-9d51-e9a17ef31afc.png)

Pipeline을 실행할 때 각 컨테이너는 Kubernetes 스케줄링에 따라 dependency를 고려하여 cluster 내에서 실행됩니다.

> Run pipeline in cluster

![](https://user-images.githubusercontent.com/31475037/112990070-970df000-91a0-11eb-853f-2747d0681532.png)

<br>

# Concepts

Kfp의 주요 concept들에 대해 소개합니다.

## Component

Component는 docker image로 containerized되있는걸 추천(reproducible or independent하게 만들기 위해)

Components는 특정 프로그램이나, 특정 entrypoint를 컨테이너 안에 represent해야 함.

각 components는 독립되어있으며, components는 같은 프로세스안에서 같이 실행되서는 안됩니다.(메모리 공유도 x)

함수 개념과 굉장히 유사(input이 있고 output이 있음)

YAML format으로 describe됨

- **Metadata**: name, description, etc
- **Interface**: input/output specifications(name, type, description, default value, etc)
- **implementation**: 주어진 arg로 어떻게 run 할고, output artifact는 어떻게 할지 정함

### data passing

Components의 개념은 함수의 개념과 매우 유사

Components code는 input data을 받아 output data을 생성

Program은 output data의 경로를 args로 받아 들여야합니다. 즉, 경로를 하드 코딩해서는 안됨.(e.g. /mnt/data/)

1. Small pices of data는 command-line args로 전달
2. Bigger data의 경우나 binary data의 경우 file에 저장됨 ⇒ file path가 전달

<br>

## Step

Step은 pipline안에 있는 component를 실행하는 것을 의미합니다.

<br>

## Experiment

Experiment는 다양한 pipeline configuration를 시도하는 workspace입니다.

Experiment 안에는 수많은 Run들이 존재합니다.

<br>

## Run and **Recurring run**

Run은 Pipeline의 single exectuion입니다. Run 각 step에 대한 runtime graph, output artifact, log를 Kubeflow Pipelines UI에서 확인 가능합니다.

**Recurring run**은 pipline 내 반복되는 run 입니다. Pipeline config, parameters, run trigger를 가집니다. concurrent run, parallel run 수를 설정합니다.

만약 Create Run시 Experiment 설정을 안해줬다면, Default Experiment에 Run이 생성됨

<br>

## Artifact

모델 train/test 과정 중에서 생성된 output들을 의미합니다.(e.g. log, model ...)

<br>

## DSL(Domain-Sepcific Language)

DSL는 관련 특정 분야에 최적화된 프로그래밍 언어입니다. 비 전문가도 쉽게 사용토록 설계되었습니다. 대표적인 케이스가 DSL compiler를 이용해 python 코드를 yaml spec으로 바꾸는 경우가 있습니다.

<br>

# KFP SDK

Kfp SDK는 아래 package들로 구성되어 있습니다.

### `kfp.compiler`

compiling pipline Python DSL into a workflow yaml

`kfp.compiler.Compier.compile`은 Python DSL code를 single static config(YAML format)으로 바꿔줌 ⇒ DSL compilers는 python 코드를 yaml 파일로 변환

### `kfp.components`

pipeline components와 interacting하는 패키지

- `kfp.components.func_to_container_op`는 python function을 pipeline component로 바꿈. You can then call the **factory function** to construct an instance of a pipeline task (ContainerOp) that runs the original function in a container.
- `kfp.components.load_component_from_file`은 pipeline component를 로드함
- `kfp.components.load_component_from_url`는 URL로 부터 로드

### `kfp.dsl`

`kpf.dsl`는 DSL을 정의하고, pipeline components들과 interact함

- `kfp.dsl.PipelineParam`은 pipeline parameter를 표현
- `kfp.dsl.component`는 DSL fuctions에 대한 decorator
- `kfp.dsl.pipeline`는 python function에 대한 decorator
- `kfp.dsl.types`는 kfp SDK가 정의한 type list ⇒ like String, Integer, Float, Bool
- `kfp.dsl.VolumeOP`는 PVC를 생성하는 pipeline task(op) 표현
- `kfp.dsl.PipelineVolume`는 step별로 이동하는 data의 volume에 대해 표현

### `kfp.Client`

Kubeflow Pipelines API와 통신

- `kfp.Client.create_experiment`는 pipeline experment를 생성하고 experiment object를 반환
- `kfp.Client.run_pipeline`는 pipeline을 실행하고, run object 반환
- `kfp.Client.create_run_from_pipeline_func`는 pipeline을 컴파일하고, Kubeflow Pipeline에 submit하고 실행시킴
- `kfp.Client.upload_pipeline_version`는 pipeline을 Kubeflow Pipelines에 upload(version과 같이)



<br>

# Building Pipelines and Components

4가지 SDK 빌딩 방식 소개

<br>

## 1. Creating components within your application code

Notebook server에서 코드를 다 짠다면 최적의 방식으로 보임.

Create a pipeline component inside your Python application, as part of the application.

The DSL code for creating a component therefore runs inside your Docker container.

### 1. Write Python code

```python
def my_func(a:str, b:str) -> str:
    ...
```

### 2. function to component

`kfp.dsl.python_component`를 사용해 python function을 component로 변환

```python
@kfp.dsl.python_component(
  name='example',
  description='example',
)
def my_func(a:str, b:str) -> str:
    ...
```

### 3. create container image

`kfp.compiler.build_python_component`를 사용해 component를 담은 image(container) 생성

```python
my_op = kfp.compiler.build_python_component(
  component_func=my_python_func,
  staging_gcs_path=OUTPUT_DIR,
  target_image=TARGET_IMAGE)
```

### 4. Write pipeline

`kfp.dsl.pipeline`을 이용해 pipeline을 만듦

```python
@kfp.dsl.pipeline(
  name='pipeline',
  description='pipeline',
)
def pipeline(param_1: PipelineParam, param_2: PipelineParam):
  step = op(a='a', b='b')
```

### 5. Compile the pipeline

`kfp.compiler.Compiler.compile`을 이용해 pipeline 코드를 python에서 YAML format으로 변경

```python
kfp.compiler.Compiler().compile(pipeline, 'pipeline.zip')
```

### 6. run pipeline

clinet를 이용해 pipeline을 업로드

```python
client = kfp.Client()
exp = client.create_experiment(name='example')
run = client.run_pipeline(exp.id, 'pipeline', 
  'pipeline.zip')
```

<br>

## 2. Creating components from existing application

기존 컨테이너화된 app을 components로 만들어 Python 애플리케이션 외부에서 component와 pipeline을 build

이 방식을 이용해서 reproducible(재사용성) 증가 시키고 보다 편리하게 관리

### 1. Build a Docker image and upload it to a registry

`kfp.compiler.build_docker_image`를 이용해 dockerfile을 빌드해 image로 만들수 있음

### 2. Use the Pipelines DSL to create a function defining the interactions with the component's Docker container.

component function은 `kfp.dsl.ContainerOP`를 반환해야함

ContainerOP는 an object that defines a pipeline component from a container.

```python
@kfp.dsl.component
def my_component(my_param):
  ...
  return kfp.dsl.ContainerOp(
    name='My component name',
    image='gcr.io/path/to/container/image'
  )
```

### 3. Define a pipeline and include all components

`@kfp.dsl.pipeline`로 function decorating

```python
@kfp.dsl.pipeline(
  name='My pipeline',
  description='My machine learning pipeline'
)
def my_pipeline(param_1: PipelineParam, param_2: PipelineParam):
  my_step = my_component(my_param='a')
```

### 4. Compile the pipeline to generate a compressed YAML definition of the pipeline

```
@kfp.compile.Complier.complie`이나 command로 `dsl-compile
kfp.compiler.Compiler().compile(my_pipeline, 'my-pipeline.zip')
dsl-compile --py [path/to/python/file] --output my-pipeline.zip
```

### 5. run pipeline

```
kfp.Client.create.experiment
kfp.Client.run_pipeline
client = kfp.Client()
my_experiment = client.create_experiment(name='demo')
my_run = client.run_pipeline(my_experiment.id, 'my-pipeline', 'my-pipeline.zip')
```

<br>

## 3. Creating components within your application code

Create lightweight Python components that do not require you to build a container image. Lightweight components simplify prototyping and rapid development, especially in a Jupyter notebook environment.

1. Write your code in a Python function.

2. Use `[kfp.components.func_to_container_op](<https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.components.html#kfp.components.func_to_container_op>)` to convert your Python function into a pipeline component

3. If you stored your lightweight component in a file as described in the previous step, use `[kfp.components.load_component_from_file](<https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.components.html#kfp.components.load_component_from_file>)` to load the component:

4. Write a pipeline function using the `kfp.dsl` to define the pipeline. Use the `[kfp.dsl.pipeline](<https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.dsl.html#kfp.dsl.pipeline>)` to build a pipeline from your pipeline function.

5. Compile the pipeline to generate a compressed YAML definition of the pipeline.

   The Kubeflow Pipelines service converts the static configuration into a set of Kubernetes resources for execution.

   To compile the pipeline, you can choose one of the following options:

   - Use the `[kfp.compiler.Compiler.compile](<https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.compiler.html#kfp.compiler.Compiler>)` method:
   - Use the `dsl-compile` command on the command line.

6. Run pipeline

<br>

## 4. Using prebuilt, reusable components in your pipeline

Reusable, prebuilt한 components는 누군가가 yaml 파일로 describe된 파일을 pipeline 상에서 load 하는 방식입니다.

이 방식이 현재 kfp에서 밀고 있는 방식이며, `kfp.dsl.ContainerOp` 대신 이 방식 써달라고 warning 뜸

- yaml 파일 describe

  ```yaml
  name: train mnist model
  description: train mnist model
  inputs:
    - {name: storage, type: string}
  outputs:
    - {name: logdir, type: string}
  implementation:
    container:
      image: train_image_location
      command: ['python', '/mnist.py']
      args: ['--storage', {inputValue: storage}]
      fileOutputs: 
        logdir: /logdir.txt
  ```

- yaml로 describe된 yaml file을 pipeline에서 load `kfp.components.load_component_from_file(filename)` or `kfp.components.load_component_from_url(url: str, auth=None)`

  ```python
  my_op = kfp.components.load_component_from_file('./train/component.yaml')
  ```

- pipeline 작성 및 compile하고 client를 통해 run

  ```python
  @kfp.dsl.pipeline(
    name='My pipeline',
    description='My machine learning pipeline'
  )
  def my_pipeline(param_1: PipelineParam, param_2: PipelineParam):
    my_step = my_op(a='a', b='b')
  
  kfp.compiler.Compiler().compile(my_pipeline, 'my-pipeline.zip')
  client = kfp.Client()
  my_experiment = client.create_experiment(name='demo')
  my_run = client.run_pipeline(my_experiment.id, 'my-pipeline', 'my-pipeline.zip')
  ```



<br>

**참조 강의**

[Introduction to the Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/sdk/sdk-overview/)

[도메인 특화 언어(DSL)에 관한 설명 | JetBrains MPS](https://www.jetbrains.com/ko-kr/mps/concepts/domain-specific-languages/)

[Concepts](https://www.kubeflow.org/docs/components/pipelines/overview/concepts/)

[Data science workflows on Kubernetes with Kubeflow Pipelines (Part 1) | Manceps](https://www.manceps.com/articles/tutorial/data-science-workflows-on-kubernetes-with-kubeflow-pipelines-part-1)