---
layout: post
title: MLOps Zero to Hero 15 - kfp(kubflow pipeline) SDK
tags: [MLOps]
use_math: true
---

# Overview

Kfp(kubeflow pipeline)은 kubeflow echo system의 한 부분으로, 대규모 ML 모델을 train 및 test하고 이를 효과적으로 관리할 수 있게 도와줍니다. Kfp는 Kubeflow의 가장 중요한 기능 중 하나이며, ML Experiment를 reproducible, reusable하게 만듭니다.

Pipeline의 각 node는 container이며, DAG(Directed Acyclic Graph)로 표현됩니다.

> kfp example

![](https://user-images.githubusercontent.com/31475037/112990077-98d7b380-91a0-11eb-9d51-e9a17ef31afc.png)

Pipeline을 실행할 때 각 컨테이너는 Kubernetes 스케줄링에 따라 dependency를 고려하여 cluster 내에서 실행됩니다.

> Run pipeline in cluster

![](https://user-images.githubusercontent.com/31475037/112990070-970df000-91a0-11eb-853f-2747d0681532.png)

<br>

# Concepts

Kfp의 주요 concept들에 대해 소개합니다.

## Component

Component는 docker image로 containerized되있는걸 추천(reproducible or independent하게 만들기 위해)

Components는 특정 프로그램이나, 특정 entrypoint를 컨테이너 안에 represent해야 함.

각 components는 독립되어있으며, components는 같은 프로세스안에서 같이 실행되서는 안됩니다.(메모리 공유도 x)

함수 개념과 굉장히 유사(input이 있고 output이 있음)

Components의 개념은 함수의 개념과 매우 유사 => containerzied 시켜 independent하게 만듦

Program은 output data의 경로를 args로 받아 들여야합니다. 즉, 경로를 하드 코딩해서는 안됨.(e.g. /mnt/data/)

Components code는 input data을 받아 output data을 생성

YAML format으로 describe됨

- **Metadata**: name, description, etc
- **Interface**: input/output specifications(name, type, description, default value, etc)
- **implementation**: 주어진 arg로 어떻게 run 할고, output artifact는 어떻게 할지 정함

<br>

## Pipeline

Pipeline Components는 data preprocessing, data transformation, model training 등과 같은 ML workflow(pipeline)를 수행합니다.

Pipeline configuration에는 pipeline 실행에 parameter 정의, component들의 input, output이 정의됩니다.

데이터 preprocessing부터 모델 train/test까지를 pipeline으로 구축

<br>

## Step

Step은 pipline안에 있는 component를 실행하는 것을 의미합니다.

<br>

## Experiment

Experiment는 다양한 pipeline configuration를 시도하는 workspace입니다.

Experiment 안에는 수많은 Run들이 존재합니다.

<br>

## Run and **Recurring run**

Run은 Pipeline의 single exectuion입니다. Run 각 step에 대한 runtime graph, output artifact, log를 Kubeflow Pipelines UI에서 확인 가능합니다.

**Recurring run**은 pipline 내 반복되는 run 입니다. Pipeline config, parameters, run trigger를 가집니다. concurrent run, parallel run 수를 설정합니다.

만약 Create Run시 Experiment 설정을 안해줬다면, Default Experiment에 Run이 생성됨

<br>

## Artifact

모델 train/test 과정 중에서 생성된 output들을 의미합니다.(e.g. log, model ...)

<br>

## DSL(Domain-Sepcific Language)

DSL는 관련 특정 분야에 최적화된 프로그래밍 언어입니다. 비 전문가도 쉽게 사용토록 설계되었습니다. 대표적인 케이스가 DSL compiler를 이용해 python 코드를 yaml spec으로 바꾸는 경우가 있습니다.

<br>

# KFP SDK

Kfp SDK는 아래 package들로 구성되어 있습니다.

### `kfp.compiler`

compiling pipline Python DSL into a workflow yaml

`kfp.compiler.Compier.compile`은 Python DSL code를 single static config(YAML format)으로 바꿔줌 ⇒ DSL compilers는 python 코드를 yaml 파일로 변환

### `kfp.components`

pipeline components와 interacting하는 패키지

- `kfp.components.func_to_container_op`는 python function을 pipeline component로 바꿈. You can then call the **factory function** to construct an instance of a pipeline task (ContainerOp) that runs the original function in a container.
- `kfp.components.load_component_from_file`은 pipeline component를 로드함
- `kfp.components.load_component_from_url`는 URL로 부터 로드

### `kfp.dsl`

`kpf.dsl`는 DSL을 정의하고, pipeline components들과 interact함

- `kfp.dsl.PipelineParam`은 pipeline parameter를 표현
- `kfp.dsl.component`는 DSL fuctions에 대한 decorator
- `kfp.dsl.pipeline`는 python function에 대한 decorator
- `kfp.dsl.types`는 kfp SDK가 정의한 type list ⇒ like String, Integer, Float, Bool
- `kfp.dsl.VolumeOP`는 PVC를 생성하는 pipeline task(op) 표현
- `kfp.dsl.PipelineVolume`는 step별로 이동하는 data의 volume에 대해 표현

### `kfp.Client`

Kubeflow Pipelines API와 통신

- `kfp.Client.create_experiment`는 pipeline experment를 생성하고 experiment object를 반환
- `kfp.Client.run_pipeline`는 pipeline을 실행하고, run object 반환
- `kfp.Client.create_run_from_pipeline_func`는 pipeline을 컴파일하고, Kubeflow Pipeline에 submit하고 실행시킴
- `kfp.Client.upload_pipeline_version`는 pipeline을 Kubeflow Pipelines에 upload(version과 같이)



<br>

**참조 강의**

[Introduction to the Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/sdk/sdk-overview/)

[도메인 특화 언어(DSL)에 관한 설명 | JetBrains MPS](https://www.jetbrains.com/ko-kr/mps/concepts/domain-specific-languages/)

[Concepts](https://www.kubeflow.org/docs/components/pipelines/overview/concepts/)

[Data science workflows on Kubernetes with Kubeflow Pipelines (Part 1) | Manceps](https://www.manceps.com/articles/tutorial/data-science-workflows-on-kubernetes-with-kubeflow-pipelines-part-1)