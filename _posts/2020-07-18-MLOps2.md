---
layout: post
title: MLOps Zero to Hero 1 - Data 관리
tags: [MLOps]
use_math: true
---

# Data

이번 포스트에선 ML 오픈 소스 생태계 중에서 Data 영역에 있는 툴들을 살펴보겠습니다.

> ML 오픈소스 생태계

![](https://user-images.githubusercontent.com/31475037/92839296-be76b880-f41a-11ea-815e-3fe6d5fdae59.png)



ML 학습은 종래의 소프트웨어 개발자가 알고리즘을 짜는 것이 아닌 데이터를 모델에 넣어 학습시키기에 data를 수집하는 것이 굉장히 중요한 업무입니다. 모델 학습시 입력 데이터가 쓰레기면 결과값도 쓰레기니까요.(Garbage in, Garbage out)

그런데 이런 data를 처리하는데에는 다음과 같은 문제점들이 존재합니다.

- 충분치 않은 데이터
- Class imbalance한 데이터 
- 잘못 label된 데이터 

다음은 실제 ML engineer들이 업무에서 가장 많이 하는 일에 대한 설문입니다. 재밌게도 데이터를 올바르게 만드는 작업이 굉장히  많은 시간을 잡아먹는군요.

> ML engineer들이 실제 업무에서 가장 많이 하는 일

![](https://user-images.githubusercontent.com/31475037/92839290-bd458b80-f41a-11ea-876d-0d7c1838c68c.png)



<br>

## Dataset Cost

ML project를 위해선 레이블된 데이터가 많이 필요합니다. *(예외: Reinforcement learning, GAN, unsupervised learning or self-supervised learning)* 

그런데 이러한 데이터 레이블링엔 굉장히 많은 돈이 들어갑니다. 왜냐하면 수많은 annotator(레이블링 하는 사람)들이 여러번 레이블링을 한 뒤, 전문 검수자들이 크로스 체킹을 통해 검수를 하는 과정이 들어가기에 그렇습니다. 이런 레이블링에 드는 비용 문제를 해결하기 위해서 **크라우드 소싱(Amazon Mturk)**나 **auto annotation tool**을 제작하곤 합니다.

> 레이블링엔 돈이 많이 든다....

![](https://user-images.githubusercontent.com/31475037/92839281-bae33180-f41a-11ea-8e5c-cbeaa10e1417.png)

이러한 데이터셋 레이블링 pipeline 구축은 MS에서 만든 [COCO dataset](https://arxiv.org/pdf/1405.0312.pdf)이 어떻게 레이블링 되었는가에 대한 논문을 가이드라인으로 삼을만 합니다. COCO dataset의 경우엔 annotator는 Amazon Mturk를 통해 값싼 비용으로 레이블링 후, 이를 검수하는 검수 전문가를 훈련시킨 뒤, 여러 전문가들이 공통된 rule을 만들어 크로스 체킹을 통해 레이블링이 제대로 되있는지 검사합니다. 일련의 검수 과정을 통해,  레이블링 퀄리티가 떨어지는 노동자의 경우 더 이상 일감을 주지 않습니다. 즉, annotator를 직접 훈련시키지는 않지만 전문 검수자들의 크로스 체킹을 통해 레이블링 퀄리티가 떨어지는 annotator들을 해고함으로써 노동자들을 훈련시킵니다.

예시로 아래 이미지는 여우에대해 bbox를 치는 작업인데, 일반적으로 픽셀 단위의 오차 범위 내에서 여우가 bbox 안에 들어오도록 레이블링 합니다.

> annotator를 학습 시키는 것은 굉장히 중요함

![](https://user-images.githubusercontent.com/31475037/92839268-b74faa80-f41a-11ea-9b9c-54dc39334ec8.png)

<br>

# Data Storage

이렇게 레이블링 된 데이터 혹은 수집된 데이터들은 data storage에 저장이 됩니다.

Storage system에는 다양한 방식이 있지만 중요한 몇가지만 짚고 넘어가겠습니다.

<br>

## File system

File system은 기본적인 시스템입니다.

- 단위는 텍스트 또는 바이너리 "파일"이며 versioning(버전관리)이 안되있습니다. 
- 간단히 local disk에 mount하기만 하면 됩니다.
- NFS(Network File System) 구축시 네트워크를 통해 여러 pc에서 storage로 접속 가능합니다.
- HDFS(Hadoop Distributed File System) 구축시 여러 stroage에 분산 저장이 가능합니다.

> File System

<center><img src="https://cdn.ttgtmedia.com/rms/onlineImages/TT_tree_mobile.jpg"></center>

<br>

## DB(DataBase)

위의 File System에서 발전한 방식이 DB에 저장하는 방식입니다. 

DB는 크게  **RDBMS**(Relational Database Management System)와 **NoSQL**(Not only SQL or No SQL)로 나뉩니다.

### File System에서 RDBMS로의 발전

File System은 복잡도가 낮지만, 데이터를 각각의 파일 단위로 저장,처리하기에 데이터에 대한 **중복성**, **무결성** 문제가 생기게 되었고 이를 해결하기 위해 RDBMS(Relational Database Management System)가 등장했습니다..

### RDBMS의 특징

- **물리적 독립성**: DB 사이즈를 늘리더라도 관련 응용 프로그램을 수정 할 필요가 없음
- **논리적 독립성**: DB는 논리적 구조로 다양한 응용 프로그램의 논리적 요구 만족
- **데이터의 무결성**: 여러 경로를 통해 잘못된 데이터가 발생하는 경우의 수를 방지, 데이터 유효성 검사
- **데이터의 중복성**: 자료의 중복과 데이터의 중복성 문제 해결
- table을 정의하고 이 table에 맞지 않는 데이터는 저장되지 않음

> RDBMS는 Table을 정의하고 Table끼리의 관계를 정의해 데이터를 저장함

![](https://i.ytimg.com/vi/6BSlwKkgCYU/maxresdefault.jpg)

### 대표적인 RDBMS

**MySQL**

MySQL은 오픈소스 중에서 가장 대표적이면서 복잡도가 낮은 시스템에서 사용하기 좋은 DB입니다. 그렇지만 RDBMS 성능에 가장 중요한 영향을 미치는 Join이 NL(Netsted Loop) join 계열과 Sort Merge join 계열만 지원해, 시스템의 복잡도가 올라갈수록 성능이 저하됩니다.

**PostgreSQL**

지속적이고 빠르며 확장 가능한 DB입니다. 기존 MySQL은 확장성이 부족하고 JSON과 같은 다른 포맷으로 변환하는 작업이 까다롭거나 했습니다. 그런 측면에선 PostgreSQL이 우월합니다. 그렇지만 확장성이 좋은 대신, MySQL에 비해 CRUD(Create Read Update Delete) 성능이 좋지 않습니다.

### NoSQL

기존 RDBMS는 데이터의 무결성, 중복성등을 보장해주는 대신, table을 정의하고 정의한 table에 맞게만 데이터를 저장할 수 있습니다. 또한 RDBMS의 경우 정규화 작업을 통해 무결성, 중복성을 없애주어야 하는데, 이러한 정규화 과정을 거치게 되면 table이 여러개로 쪼개지게 되고 각각의 table끼리 foreign key(외래키)를 통해 relation(관계)를 맺어주어야 하며, 이로인해 CRUD 성능이 떨어지게 됩니다. 특히나 read 성능이 떨어지게되 기존 3NF 까지 정규화 하던것을 1NF나 2NF까지만 하는 **반정규화**를 하기 시작합니다. 즉, read 성능을 높이기 위해서 데이터의 무결성과 중복성을 포기하는 것이죠.

> 반정규화, Read 성능을 높이기 위해 쓰임

<center><img src="https://user-images.githubusercontent.com/31475037/95030625-f4425080-06eb-11eb-9a63-fc55166e5f7f.png"></center>

그러던 와중 기존 RDBMS처럼 table에 정의가 힘든 경우(SNS의 게시글)나 혹은 높은 CRUD 성능이 필요한 경우들이 생겨나기 시작했습니다. 이러한 요구에 발맞춰 느슨한 table(schema)을 지향하며 대량의 분산 데이터를 CRUD하는데 특화된 NoSQL(Not Only SQL or NoSQL)이 나왔습니다.

RDBMS의 DB 설계 방법론과는 다른 CAP 이론을 기반으로한 NoSQL 설계 방법론이 등장하게 됩니다.

### CAP 이론

**1. 일관성(Consistency)**

일관성은 동시성 또는 동일성이라고도 하며 다중 클라이언트에서 같은 시간에 조회하는 데이터는 항상 동일한 데이터임을 보증하는 것을 의미합니다. 이것은 RDBMS가 지원하는 가장 기본적인 기능이지만 일관성을 지원하지 않는 NoSQL 을 사용한다면 데이터의 일관성이 느슨하게 처리되어 동일한 데이터가 나타나지 않을 수 있습니다. 

**2. 가용성(Availability)**

가용성이란 모든 클라이언트의 읽기와 쓰기 요청에 대하여 항상 응답이 가능해야 함을 보증하는 것입니다. 가용성을 가진 NoSQL 은 클러스터 내에서 몇 개 노드가 망가지더라도 정상적인 서비스가 가능합니다.(다른 노드가 대체해서 작동)

**3. 분할 허용성(Partition tolerance)**

분할 허용성이란 분할된 네트워크 환경에서 동작하는 시스템에서 네트워크가 단절되거나, 네트워크 데이터의 유실이 일어나더라도 각 지역 내 시스템은 정상적으로 동작해야 함을 의미합니다.

### 저장 방식에 따른 NoSQL 분류

**1. Key-Value Model**

가장 기본적인 형태의 NoSQL이며 key-value 구조를 갖습니다. 단순한 저장구조로 인하여 복잡한 조회 연산을 지원하지 않습니다. 고속 읽기와 쓰기에 최적화된 경우가 많습니다. 단점으론 하나의 요청에 다수의 데이터 조회 및 수정 연산이 발생하면 트랜잭션 처리가 불가능하여 데이터 정합성을 보장할 수 없습니다. *ex) Redis*

**2. Document Model**

key-value 모델을 개념적으로 확장한 구조로 하나의 key에 하나의 doc을 저장하고 조회합니다.

논리적인 데이터 저장과 조회 방법이 RDBMS와 유사합니다. doc ID 에 대한 인덱스를 생성해 인덱스를 사용하여 O(1) 시간 안에 문서를 조회할 수 있습니다. 대부분의 경우 B트리(B+트리) 인덱스를 사용해 인덱스를 생성합니다.  B트리 자료구조는 크기가 커지면 커질수록 새로운 데이터를 입력하거나 삭제하거나 할때, B트리 구조에 변화가 생겨 읽기 성능이 떨어지게 됩니다. 그렇기 때문에 읽기와 쓰기의 비율이 7:3 정도일 때 가장 좋은 성능을 보입니다. *ex) MongoDB*

**3. Column Model**

하나의 key에 여러 개의 column이름과 column값의 쌍으로 이루어진 데이터를 저장하고 조회합니다. *ex) Big Table*

> NoSQL의 종류

<center><img src="https://www.simplilearn.com/ice9/free_resources_article_thumb/the-types-of-nosql-databases.jpg"></center>

<br>

## Data Lake with NoSQL

현실 세계의 데이터들의 대다수는 table에 정의하기 어렵기에 나타난 것이 NoSQL이라 했습니다. 이를 통해 raw data들을 데이터의 정합성이나 중복성 조회 없이 쑤셔 넣어 구축한 것이 바로 Data Lake입니다. NoSQL로 정의된 Data Lake에서 Data Engineer가 유의미한 data의 feature들을 추출합니다.

> Data Lake

![](https://user-images.githubusercontent.com/31475037/94651768-f2673e80-0333-11eb-86b7-7f5f67cdb003.png)





<br>

**강의**

[Full Stack Deep Learning](https://course.fullstackdeeplearning.com/)