---
layout: post
title: Frequentist and Bayesian
tags: [Math]
use_math: true
---

# Frequentist Inference

Statistics의 주요 목표 중 하나는 알 수 없는 population의 parameter(모수)를 추정하는 것 입니다. 이러한 parameter를 근사하기 위해 estimator를 사용합니다. 여기서 말하는 parameter의 대표는 바로 mean과 varaince 입니다.

Frequentist 입장에서의 estimator는 크게 2가지 방식으로 나뉩니다.

### Point Estimation(점 추정)

Population으로 부터 sample을 추출하고, 추출된 sample의 통계량(mean, variance)를 통해 population의 parameter를 근사 하는 추정 방식입니다.

### Interval Estimation(구간 추정)

Point estimator와 달리 interval estimation은 가능한 값 범위를 지정하여 parameter를 추정합니다. 즉 point estimation과는 다르게 존재할 구간을 확률적으로 추정하는 방식입니다.

대표적인 방식이 바로 confidence interval(신뢰 구간) 방식입니다. Confidence interval이란 이 구간 내에 실제 population이 존재할 것으로 예측되는 구간으로 정의가 되며, 90%, 95%, 99% confidence interval 등 다양한 정도의 구간 추정이 가능합니다. 이 중 가장 널리 사용되는 것은 95% confidence interval 입니다. 이는 예측된 구간 내에 실제 population mean이 있을 가능성이 95%라고 신뢰할 수 있는 구간의 의미입니다.

<br>

## The Bootstrap

Frequentist inference의 대부분은 "좋은" estimator의 사용에 중점을 둡니다. 

그렇다면 어떻게 해야 더 좋은 estimator를 만들까요? 그 중 대표적인 방법론이 바로 bootstrap입니다. Bootstrap이라고하는 기술은 resampling을 통해 estimator의 population을 더 정확히 추정하는 방법입니다. 

Bootstrap은 statistic과 machine learning에서의 정의가 약간 다르며 다음과 같습니다.

Statistic에서의 bootstrap은 resampling을 통해 좀 더 정확한 mean/variance를 추정하는 방법을 말합니다.

Machine learning에서는 resampling을 통해 학습 데이터를 늘리는 방식을 말하며, 이를 통해 데이터 셋 내에 데이터 분포가 고르지 않을 때 유용합니다. Bootstrap aggregating의 줄임말인 **bagging**이라고도 불립니다.

<br>

# Bayesian Inference

베이즈 정리를 이해하기 위해선 다음 성질들을 알아야 합니다.

**Conditional Probability(조건부 확률)**

Conditional probability는 전체 sample space가 아닌 특정 event만 주목하는 확률입니다.

아래 그림의 예시에서 전체 sample space **S**에서 sub space **B**만을 주목한 뒤, **B**안에서의 **A and B**일 확률을 찾는것입니다.

> 대표적인 예시

<center><img src="https://user-images.githubusercontent.com/31475037/68566747-933dd880-049a-11ea-9214-056b2430f5d7.PNG"></center>

[Conditional Probability Demo](http://setosa.io/conditional/)를 통해 개념을 잡아 봅시다.

<br>

## **Joint Probability(결합 확률)**

Joint probability란 **두 event이 순차적으로 연속해서 일어날 확률** 혹은 **시간적으로 동시에 일어날 확률**을 의미합니다. 

> Joint Probability

$$
P(A, B)= P(B) \cdot P(A|B) = P(A) \cdot P(B | A)
$$

<br>

## **Marginal Probability(주변 확률)**

Joint probability가 주어진 상태에서 오직 한개의 random variable의 확률 분포를 알고 싶을 때 사용하는 방법입니다. 보통 summing out 혹은 marginalize 한다고 말합니다.

다음 예시는 b가 가지는 event가 true/false 일 경우, law of total probability에 의해 생성된 결과물입니다. law of total probability란 전체 probability의 합이 1이 되는 법칙입니다.

> Law of total probability에 의해 계산된 marginal probability

![](https://user-images.githubusercontent.com/31475037/68566970-2a0a9500-049b-11ea-88e5-f7b631a1b2f1.PNG)

> joint probability를 알면 개별 random variable의 확률 계산 가능

![](https://user-images.githubusercontent.com/31475037/68569567-c0da5000-04a1-11ea-9b82-3f3e9f211b8d.PNG)

<br>

## **The Chain Rule of Conditional Probability**

Joint probability distribution은 chain rule에 의해 factorization 될 수 있습니다.

입력으로 들어온 joint probability에 대해 conditional probability로 분해될 수 있습니다.



> chain rule

<center><img src="https://user-images.githubusercontent.com/31475037/68569820-74434480-04a2-11ea-950a-1d3cdfcecb8b.PNG"></center>
> example

<center><img src="https://user-images.githubusercontent.com/31475037/65024604-27466480-d970-11e9-8692-3bf404d9c80b.PNG"></center>

<br>

## **Independence**	

chain rule을 이용해 factorization을 하게 되면 파라미터 수가 많아 계산량이 커질수 밖에 없습니다. 이러한 문제를 해결하기 위해 random variable 간의 indepence한 특성을 이용해줍니다.

> random variable 끼리 independence 할 때

![](https://user-images.githubusercontent.com/31475037/68570088-28dd6600-04a3-11ea-96b6-1a305b05d5dd.PNG)



다음 예시는 random variable 간 independence한 성질을 이용해 파라미터 수가 줄어든 경우 입니다.

> 예시

![](https://user-images.githubusercontent.com/31475037/68570278-9db0a000-04a3-11ea-83dc-479d1367607a.PNG)



<br>

## Bayes' Rule(베이즈 정리)

베이즈 정리는 새로운 정보(evidence)를 토대로 어떤 사건에 대한 가설의 신뢰도(확률)을 갱신해 나가는 방법입니다(a method to update belief on the basis of new information)

베이지안 관점에서의 확률은 어떤 가설(주장)에 대한 신뢰도를 나타냅니다.

기존의 통계학에서는 엄격하게 확률 공간을 정의하거나 집단(모집단 혹은 표본집단)의 분포를 정의하고 그 뒤에 계산을 통해 확률을 계산합니다. 반면에 베이지안 관점의 통계학에서는 사전 확률과 같은 **경험에 기반한 선험적인, 혹은 불확실성을 내포하는 수치**를 기반으로 하고, 거기에 추가 정보(evidence)를 바탕으로 확률을 갱신합니다.(posterior)

> 베이즈 정리

![](https://miro.medium.com/max/500/1*2Ixe8hsTASXjMXt9TySHGA.png)



**P(H)**: H의 prior - evidence를 관측하기 전의 신뢰도(확률)

**P(e)**: e의 prior - 현재의 증거(evidence)

**P(e|H)**: 관찰된 evidence에 기초한 어떤 가설에 대한 가능성(이 가설을 지지하는 정도) - liklihood이다.

**P(H|e)**: 관찰된 evidence에 기초하여 얼마나 신뢰(확률)할 수 있는가? - evidence를 관측한 후의 신뢰도(확률)



좀 더 자세한 예시는 다음 글에서 나옵니다.

[medium](https://medium.com/bright-minds-analytica/bayes-theorem-explained-66f572b875f6)

<br>

# Frequentist and Bayesian

일반적인 확률의 개념은 실험을 반복적으로 (예를 들어, 카드를 뽑는 것) 했을 때 나오는 빈도를 확률로 표현합니다.

하지만 이 방법은 실험을 반복 할 수없는 경우에는 적용이 불가 합니다. 

예를들어, 의사가 환자를 진찰하고 병에 걸렸는지 아닌지 판단한다고 해봅시다. 의사가 환자를 진찰한 후 50%의 확률로 병에 걸렸을 거라고 말합니다. 이 경우 50%의 의미가 우리가 일반적으로 아는 확률인가요?

의사가 환자를 똑같은 상태로 복제 해 여러번 실험 할 수 없습니다. 동일한 증상이 있을 수 있지만, 환자의 상태는 다 다릅니다. 

이럴 땐, 확률이 믿음의 정도를 나타내는데, 1은 환자가 병에 걸렸다는 절대적 믿음을 나타내고 0은 환자가 병에 걸리지 않았다는 절대적인 믿음을 나타냅니다. 

전자인 실험을 반복적으로 해 확률을 도출하는 방식이 frequency statistic이고,  후자인 의사가 환자를 진찰해 확률적으로 결과를 말해주는 것이 bayesian statistic입니다.



<br>

**참고 강의**

[Brown University](https://seeing-theory.brown.edu/index.html?fbclid=IwAR3TtRabvYmRyUD_OuMNRR7EDJ1cDzENps9mAYD23OznGIVJkM86k1zG4J8#firstPage)

**[Deeplearning Book](https://www.deeplearningbook.org/)**

[medium](https://medium.com/bright-minds-analytica/bayes-theorem-explained-66f572b875f6)