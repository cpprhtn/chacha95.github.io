---
layout: post
title: Statistical Analysis
tags: [Math]
use_math: true
---

# Covariance(공분산)

확률 변수의 상관정도를 나타내는 값입니다.

확률 변수 2가지가 있고, 이 확률 분포들이 어떻게 분포 되어 있는지 알고 싶을 때, 가장 먼저 X의 평균, Y의 평균을 구합니다.

두 확률변수 X와 Y의 covariance는 다음과 같이 정의됩니다.

> Covariance 식

$$
Cov[X, Y] = E[(X-E[X])(Y-E[Y])]
$$
Covariance는 서로 다른 변수들 사이에서 얼마나 의존하는지 수치적으로 표현하는 방식입니다. Covariance는  "어떤 변수(X)가 평균으로부터 증가 혹은 감소 경향을 보일 때 이런 경향을 Y가 얼마나 따라하는가?"에 대한 지표 입니다.

이러한 covariance를 이용해 만든 정방 행렬(nxn)이 바로 Covariance matrix 입니다.

특히나 covariance matrix에서 eigenvector와  eigenvalue를 찾는 것이, 데이터의 principal axis를 찾는 것과 동일하기에 PCA와 같은 기법에서 많이 쓰입니다.

> Covaraince Matrix

$$
\begin{bmatrix}
Var[X] & Cov[X,Y] & Cov[X,Z] \\
Cov[Y,X] & Var[Y] & Cov[Y,Z]\\
Cov[Z,X] & Cov[Z,Y] & Var[Z]
\end{bmatrix}
$$



<br>

### Correlation Coefficient(상관계수)

Correlation은 Covariance를 [-1, 1] 범위로 normalize한 것입니다.

> Correlation 식

$$
\rho[X, Y] = \frac {Cov[X,Y]}{\sqrt{Var[X]\cdot Var[Y]}}
$$



 ρ 값에 따라 random variable X와 Y는 다음과 같은 관계를 가집니다.

- ρ : -1

  역의 상관관계

- ρ : 0

  무의 상관관계

- ρ : 1

  정의 상관관계

> ρ값에 따른 상관관계를 표현

![](https://user-images.githubusercontent.com/31475037/64940664-8ab49180-d89f-11e9-86b3-1c6135df58cc.PNG)

<br>

# Likelihood(가능도)

Likelihood는 continous event의 경우 특정 event를 추정하지 못하고, PDF 함수의 구간으로 확률이 계산되기에, 특정 event에 대한 추정을 하기 위해 제안된 방법입니다. Likelihood는 PDF 함수 에서의 y 값을 일어날 가능도로 보겠다는 의미입니다. 

> 가능도의 직관적인 정의 : PDF의 y 축 값

- Discrete인 경우: **가능도 = 확률**
- Continuous인 경우: **가능도 ≠≠ 확률, 가능도 = PDF 함수의 y축 값**

probability는 distribution이 주어졌을 때, data일 확률을 구하는 것이라면, likelihood는 data가 주어졌을 때 distribution일 값을 구하는 것입니다.

> likelihood와 probability

![](https://user-images.githubusercontent.com/31475037/68557593-ae4c2080-0479-11ea-8f00-75a55a7ffd7c.PNG)

[StatQuest 강의](https://www.youtube.com/watch?v=pYxNSUDSFH4)에서 잘 설명되어 있습니다.



<br>

### MLE(Maximum Likelihood Estimator)

MLE는 사건의 가능도가 최대가 되는 추정값을 구하는 방식입니다. 

데이터가 주어졌을 때, 가장 Likelihood 값을 높게 만드는 distribution을 추정하는 방식입니다.

다음과 같이 normal distribution과 data가 주어졌을때 likelihood값이 가장 높은 경우는 어떤 경우일까요?

두번째와 같은 distribution을 가졌을 때 likelihood값이 가장 커집니다.

> 다음 예시에서 likelihood값이 가장 높은 경우는 두번째 이다.

![](https://user-images.githubusercontent.com/31475037/68558937-83b09680-047e-11ea-9cb8-999096a00e99.PNG)

![](https://user-images.githubusercontent.com/31475037/68558938-84492d00-047e-11ea-8b93-2046bfedee88.PNG)

![](https://user-images.githubusercontent.com/31475037/68558939-84492d00-047e-11ea-9154-fccc32fac810.PNG)



이처럼 MLE는 데이터가 주어졌을 때, likelihood 값이 최대가 되는 distribution을 만드는 parameter θ를 구하는 것이 목표입니다.  

> MLE

![](https://user-images.githubusercontent.com/31475037/65309254-acc35200-dbc6-11e9-929d-3dbff978397d.PNG)

[StatQuest 강의](https://www.youtube.com/watch?v=Dn6b9fCIUpM)에서 잘 설명되어 있습니다.

<br>

# Information Theory

**정보이론(Information Theory)**

정보이론은 다음과 같습니다.

- 정보(information)란 놀람의 정도를 수치화

- 정보는 확률에 반비례

- 어떤 사람이 정보를 더 많이 알수록 새롭게 알 수 있는 정보는 적어짐

- 어떤 사건의 확률이 매우 높다고 가정했을 때, 그 사건이 발생해도 별로 놀라지 않는다. 즉, 이 사건은 적은 정보를 제공한다(정보량이 낮다)

- 반면 사건의 확률이 매우 낮으면, 그 사건이 발생할시 놀랍다(정보량이 많다)

- 예를 들어 해가 아침에 뜬다는 정보는 놀랍지 않기에 정보량이 적음, 하지만 오늘 아침에 개기일식이 있었다는 정보는 놀랍기 때문에 정보량이 높음

  

이런 information을 표현하는데 log 함수를 많이 쓰며, 밑으로 e 혹은 2를 사용합니다.

log의 밑으로 2를 사용하는 경우에는 bits or shannons라고 부릅니다.

> 정보량 공식

<center><img src="https://user-images.githubusercontent.com/31475037/59091784-091da100-894b-11e9-8243-07be3a7c5c86.png" width="40%"></center>
**(Shannon) Entropy**

Entropy는 이러한 정보량(놀람의 정도)들의 평균을 말합니다.

어떤 시스템에서 우리가 아는것이 많으면 많을 수록 entropy는 감소합니다.

반대로 우리가 시스템에 대해 아는것이 없다면 해당 시스템의 entorpy는 증가합니다.

> (Shannon) Entropy 공식

<center><img src="https://user-images.githubusercontent.com/31475037/59080014-89c7a780-8921-11e9-837e-14f1ccf50c39.png" width="50%"></center>
**KL-divergence(Kullbeack-Leibler 발산)**

두 probability distribution p와 q가 얼마나 다른지 측정하는 방식입니다.

KL-divergence가 0에 가깝다는 의미는 두 확률 분포가 거의 비슷하다는 의미입니다.

개념상 두 probability distribution 사이의 distance와 비슷합니다. 여기서 주의할 점은 실제 distance의 정의는 아니지만 distance와 유사한 것입니다.

p는 ground truth distribution, q는 predicted distribution입니다.

<center><img src="https://user-images.githubusercontent.com/31475037/59080015-8a603e00-8921-11e9-9e79-b32abcf35ccf.png"></center>
KL-divergence를 최소화하는것은 결국 첫번째 항 cross-entropy를 최소화하는 q를 찾는것입니다.

<center><img src="https://user-images.githubusercontent.com/31475037/59080017-8a603e00-8921-11e9-8092-ddd9b509377a.png" width="80%"></center>
여기서 KL-divergence를 통해 두 확률분포의 차를 최소한으로 만드는 것은 본질적으로 MLE를 통해 모수를 추정하는 것과 같습니다. 

<br>

**참고 강의**

[Brown University](https://seeing-theory.brown.edu/index.html?fbclid=IwAR3TtRabvYmRyUD_OuMNRR7EDJ1cDzENps9mAYD23OznGIVJkM86k1zG4J8#firstPage)

**[Deeplearning Book](https://www.deeplearningbook.org/)**

[데이터 사이언스 스쿨](https://datascienceschool.net/view-notebook/4cab41c0d9cd4eafaff8a45f590592c5/)



